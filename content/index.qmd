---
title: Mise en production des projets de data science
subtitle: |
  **[Romain Avouac, Lino Galiana]{.orange}**
# date: 
slide-number: true
footer: |
  Bonnes pratiques pour la mise en production des projets de data science
# uncomment for French presentations:
lang: fr-FR
# for blind readers:
slide-tone: false
# for @olevitt:
chalkboard: # press the B key to toggle chalkboard
  theme: whiteboard
# uncomment to use the multiplex mode:
#multiplex: true
format:
  # pick the light mode (onyxia-revealjs) or the dark mode (onyxia-dark-revealjs)
  onyxia-revealjs:
  #onyxia-dark-revealjs:
    output-file: index.html
controls: true
css: custom.css
from: markdown+emoji
---

# Introduction

## Disclaimer

- Contenu en construction : [https://linogaliana.github.io/ensae-reproductibilite-website/](https://linogaliana.github.io/ensae-reproductibilite-website/)

. . .

- Programme large

. . .

- Applications guidées

## Contexte

::: {.incremental}
- [**Qui sommes-nous ?**]{.orange}
    - des [**data scientists**]{.blue2} de l'Insee
    - frustrés par l'[**approche**]{.blue2} souvent purement [**technique**]{.blue2} de la data science
    - convaincus que les [**bonnes pratiques**]{.blue2} valent à être enseignées

- <romain.avouac@insee.fr>, <lino.galiana@insee.fr>
:::

## La notion de bonnes pratiques

- [**Origine**]{.blue2} : communauté des développeurs logiciels

::: {.incremental}
- [**Constats**]{.blue2} :
    - le [_"code est plus souvent lu qu'écrit"_]{.green2} ([Guido Van Rossum](https://fr.wikipedia.org/wiki/Guido_van_Rossum))
    - la maintenance d'un code est très coûteuse
:::

. . .

- [**Conséquence**]{.blue2} : un ensemble de [**règles informelles**]{.orange}, conventionnellement acceptées comme produisant des logiciels [**fiables**]{.orange}, [**évolutifs**]{.orange} et [**maintenables**]{.orange}


## Pourquoi s'intéresser aux bonnes pratiques ? {.smaller}

<br>

L'activité du *datascientist* tend à se rapprocher de celle du développeur :

. . .

- projets [**intenses en code**]{.orange}

. . .

- [**projets collaboratifs**]{.orange} et de grande envergure

. . .


- [**complexification**]{.orange} des données et donc des [**infrastructures**]{.orange}

. . .

- [**déploiement**]{.orange} d'applications pour valoriser les analyses

## Bonnes pratiques et reproductibilité

![](img/reprospectrum.png){height="200" fig-align="center"}

**Source** : Peng R., Reproducible Research in Computational Science, Science (2011)

## Contenu du cours

::: {.incremental}
- Voir le code comme un [**outil de communication**]{.orange}
    - [**Contrôle de version**]{.blue2} avec Git
    - [**Qualité**]{.blue2} du code
    - [**Structure**]{.blue2} des projets

- [**Travail collaboratif**]{.orange} avec Git et GitHub

- Maximiser la [**portabilité**]{.orange}

- [**Déployer**]{.orange} et [**valoriser**]{.orange} un projet de data science
:::





# Git : rappels

## Pourquoi utiliser Git ?

![](img/timeline.png){fig-align="center" height=475}

[Source](https://thinkr.fr/travailler-avec-git-via-rstudio-et-versionner-son-code/)

## Concepts essentiels

![](img/gitallinone.png){height="400" fig-align="center"}

[Source](http://fabacademy.org/2021/labs/bhubaneswar/students/deepak-chaudhry/ia_PPFP.html)

## Bonnes pratiques {auto-animate=true .smaller}

__Que versionne-t-on ?__

:::{.incremental}
- Essentiellement du [**code source**]{.orange}
- [__Pas d'outputs__]{.orange} (fichiers `.html`, `.pdf`, modèles...)
- [__Pas de données__]{.orange}, d'informations locales ou sensibles
:::

:::{.callout-note}

Pour définir des règles qui évitent de committer tel ou tel fichier, on utilise
un fichier nommé __`.gitignore`__.

Si on mélange du code et des éléments
annexes (_output_, données...) dans un même dossier, il [__faut consacrer du temps à ce fichier__]{.orange}.

Le site [`gitignore.io`](https://www.toptal.com/developers/gitignore) peut vous fournir
des modèles.

N'hésitez pas à y ajouter des règles conservatrices (par exemple `*.csv`), 
comme cela est expliqué dans [la documentation `utilitR`](https://www.book.utilitr.org/git.html?q=gitignore#gitignore).

:::

## Bonnes pratiques {auto-animate=true .smaller}

__Format des commits__

::: {layout="[40,60]"}

::: {.incremental}
- [**Fréquence**]{.orange}
    - Aussi souvent que possible
    - Le lot de modifications doit "faire sens"
- [**Messages**]{.orange}
    - Courts et informatifs (comme un titre de mail)
    - Décrire **le pourquoi plutôt que le comment** dans le texte
:::

![](img/titre-commit.png)

:::

## En pratique

::: {.incremental}
- Git est un [**logiciel**]{.orange}

- Utilisation en [**ligne de commande**]{.orange}

- Ressources sur le site :
    - [Introduction au terminal Linux](https://linogaliana.github.io/ensae-reproductibilite-website/chapters/linux101.html)
    - [Versionner son code et travailler collaborativement avec Git](https://linogaliana.github.io/ensae-reproductibilite-website/chapters/git.html)
:::





# Qualité du code

## Enjeux 

::: {.incremental}
- D'une vision utilitariste du code à une vision du code comme [**outil de communication**]{.orange}

- Favoriser la [**lisibilité**]{.orange} et la [**maintenabilité**]{.orange}

- Adopter les [**standards communautaires**]{.orange} du langage
:::

## Standards communautaires

::: {.incremental}
- [**Python**]{.blue2} : [PEP8](https://peps.python.org/pep-0008/), [PEP 257](https://peps.python.org/pep-0257/)

- La [**cohérence intra-projet**]{.orange} doit toujours primer
:::

## Outils

::: {.incremental}
- [**Linters**]{.blue2} : diagnostic de qualité du code
    - [Pylint](https://github.com/PyCQA/pylint)

- [**Formatters**]{.blue2} : application automatique des standards
    - [Black](https://github.com/psf/black)
:::




# Structure des projets

## Enjeux

::: {.incremental}
- Favoriser la [**lisibilité**]{.orange} et la [**maintenabilité**]{.orange}

- Enjeux spécifiques à la data science
    - [**Expérimentation**]{.blue2}
    - [**Non-linéarité**]{.blue2}
    - [**Reproductibilité**]{.blue2}

- Adopter les [**standards communautaires**]{.orange} du langage
:::

## Principes généraux

::: {.incremental}
- Les données sont [**immuables**]{.orange}
    - Pas de modifications manuelles
    - [**Stockage externe**]{.blue2} (ex : S3)

- [**Notebooks**]{.orange} : pour l'[**exploration**]{.orange} et la [**communication**]{.orange}
    - Reproductibilité limitée
    - Mal gérés par le contrôle de version

- Favoriser une structure [**modulaire**]{.orange}
  - Utiliser des [**fonctions**]{.blue2} contenues dans des [**modules**]{.blue2}

- [**(Auto-)documenter**]{.orange} son projet
:::

## Standards communautaires / outils

::: {.incremental}
- [**Python**]{.orange} : [**Cookiecutters**]{.blue2} ([Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/))

- La [**cohérence intra-projet**]{.orange} doit toujours primer
:::

## Les packages

::: {.incremental}
- Un *package* est la forme maximale de [**modularité**]{.orange}
  - Contient des [**fonctions**]{.blue2} rangées dans des [**modules**]{.blue2}
  - Contient également de la [**documentation**]{.blue2}, des [**tests**]{.blue2}, des (méta-)données... 

- [**Avantages**]{.orange}
  - [**Simple**]{.blue2} à développer
  - Idéal pour favoriser la [**réutilisation**]{.blue2} du code

- [**Inconvénients**]{.orange}
  - Coût de [**maintenance**]{.blue2} élevé
:::





# Portabilité

## "It works... on my machine"

- On a construit un projet
    - Lisible et bien structuré
    - Versionné proprement avec Git

- Peut-on partager notre projet ?
    - En théorie, oui !
    - En pratique, c'est toujours plus compliqué...

![](img/IWOMM.jpg){fig-align="center"}

## L'enjeu de la portabilité

- Un code ne vit jamais dans une bulle isolée, il contient en général de nombreuses **adhérences**
    - Des **dépendances** dans le langage du projet
    - Des dépendances dans d'autres langages
    - Des **librairies système**

- Un code est **portable** s'il peut être exécuté dans un environnement différent que celui du développement

- Il nous faut de **nouveaux outils** pour atteindre une portabilité forte

## Environnements virtuels : introduction

- *Workflow* classique du data scientist qui commencerait ses premiers projets
    - Installer une distribution de `Python` sur son poste
    - Développer un projet en installant les packages nécessaires
    - Passer au projet suivant et ainsi de suite

- Quels problèmes peuvent se poser ?

----

### Environnements virtuels : enjeux

- **Conflits de version** : différents projets peuvent recquérir des versions différentes d'un même *package* ;
- **Version de Python fixe**, celle de l'installation système ;
- **Reproductibilité limitée** : difficile de dire quel projet nécessite quel package ;
- **Portabilité limitée** : difficile de fixer dans un fichier les dépendances spécifiques à un projet.

----

### Environnements virtuels : fonctionnement

- **Dossier auto-suffisant** qui contient :
    - Une installation de `Python` pour une version donnée ;
    - Des packages additionnels
et qui est **isolé** des autres environnements existants

- Développer dans des environnements virtuels vierges en début de projet est une bonne pratique pour la **reproductibilité**

----

### Environnements virtuels : implémentations

- Différentes implémentations en Python
    - L'implémentation standard est `venv`
    - L'implémentation la plus populaire en data science est `conda`

- `conda` est à la fois
    - Un *package manager* (comme `pip`)
    - Un gestionnaire d'environnements virtuels

## Environnements virtuels : installation

- `conda` est généralement installé dans le cadre de **distributions**
    - `Miniconda`
    - `Anaconda`

- `conda` est un outil en ligne de commandes (CLI)

![](img/conda-eco.png)

## Environnements virtuels : en pratique

- [Exercice guidé](https://ensae-reproductibilite.netlify.app/portability/#en-pratique)

- [Aide-mémoire des principales commandes](https://ensae-reproductibilite.netlify.app/portability/#aide-m%c3%a9moire)

## Environnements virtuels : limites

- Les **librairies système** ne sont pas gérées

- Difficile de gérer des projets faisant intervenir plusieurs langages de programmation

- Lourdeur de la phase d'installation à chaque changement d'environnement

- Peu adaptés à un environnement de production

## Conteneurs : introduction

- Idée : au lieu de distribuer la recette pour recréer la bonne machine, peut-on **distribuer directement la bonne machine** ?

- On ne peut pas distribuer des **machines physiques**

- Les **machines virtuelles** sont coûteuses et complexes à redistribuer

- Les **conteneurs** offrent un bon compromis

## Conteneurs vs. machines virtuelles

- Idée : **empaqueter** complètement l’environnement qui permet de faire tourner une application

![](img/docker-vm.png)

Source : [docker.com](https://www.docker.com/resources/what-container/)

## Conteneurs : implémentations

- Plusieurs implémentations des conteneurs

- `Docker` est largement prédominant

## Docker : installation

- [Instructions](https://docs.docker.com/get-docker/) selon le système d'exploitation

- Environnement "bac à sable" : [Play with Docker](https://labs.play-with-docker.com/)

- `Docker` est un outil en ligne de commandes (CLI)

## Docker : fonctionnement

![](img/docker-workflow.png)

Source : [k21academy.com](https://k21academy.com/docker-kubernetes/docker-and-kubernetes/)

## Docker : en pratique

- [Exercice guidé](https://ensae-reproductibilite.netlify.app/portability/#en-pratique-1)

- [Aide-mémoire des principales commandes](https://ensae-reproductibilite.netlify.app/portability/#en-pratique-1)





# Vers la mise en production

## Motivation

- La **massification** et la **diversification** des données apportent de nombreux changements
    - Le *Data Lake*
    - Le *Data Lab*
    - De nouveaux profils : *Data Scientist*, *Data Engineer*, *Data Architect*

- La majorité des projets de data science ne sont **pas déployés**

- Besoin d'**industrialisation** qui nécessite de nouveaux outils

## L'approche DevOps

- Idée : **unifier** le développement (*dev*) et l'administration système (*ops*)

- But : raccourcir le temps de développement en **déployant en continu** tout en maintenant la qualité

![](img/devops.png)

## DevOps, DataOps, MLOps ?

- Le ***DevOps*** n'intègre pas les spécificités liées à la data science

- ***DataOps*** : déploiement et maintenance de **pipelines de données**

- ***MLOps*** : déploiement et maintenance de **modèles de Machine Learning**

- Idée générale : **bonnes pratiques** pour favoriser la collaboration et faciliter les déploiements

## La mise en production

- On a construit un projet de data science **reproductible** et conforme aux **standards** des bonnes pratiques

- Pour **valoriser** le projet, il faut le **déployer** dans un environnement en lien avec les utilisateurs
    - Quel est le **format** adapté pour le valoriser ?
    - Quelle **infrastructure de production** ?
    - Comment **automatiser** le processus de déploiement ?

## Format de valorisation

- **Critères** à prendre en compte :
    - Quels sont les utilisateurs potentiels ?
    - Seulement de la mise à disposition, ou besoin d'interactivité ?
    - Entraînement en *batch* ou *online* ?
    - Besoin de *scalabilité* ?

- **Formats usuels** : API, application web, dashboard, site internet, rapport automatisé...

## Exposer un modèle via une API REST

- **API** : **interface** entre l'utilisateur (client) et le modèle entraîné

- **API REST** : permet de requêter le modèle avec une syntaxe simple (HTTP) et de manière *scalable*

![](img/api-docker.png)

## Environnement de production

- Dépend essentiellement de l'infrastructure à disposition

- Un **orchestrateur** de conteneurs répond à plusieurs besoins :
    - Adapter les ressources (**scaler**) selon les besoins
    - **Monitoring** de l'état de santé des applications
    - Déploiements **reproductibles** et **automatisés**

![](img/kubernetes-logo.png)

## Fonctionnement de Kubernetes

![](img/kubernetes-archi.png)

## L'approche CI/CD : principes

- **Intégration continue** (CI) : à chaque modification du code source, l'application est automatiquement testée et *released*

- **Déploiement continu** (CD) : les nouvelles *releases* sont automatiquement déployées

- **GitOps** : le processus est décrit sous formes de manifestes (.yaml), stockés sur un dépôt Git

## L'approche CI/CD : exemple

![](img/ci-cd.png)

## Pipeline complet

- Les données d'entrée ne sont pas fixes, il faut les intégrer dans un **pipeline** complet de données

- La représentation est faite sous forme de graphes acycliques dirigés (DAG)

![](img/pipeline.png)

## Conclusion

- On a construit un pipeline **reproductible**, **automatisé** et **scalable**

![](img/devops.png)






# Application

## Exercice guidé

- Dépôt GitHub : [https://github.com/avouacr/ensae-reproductibilite-projet](https://github.com/avouacr/ensae-reproductibilite-projet)

- Consignes sur la page [Application](https://linogaliana.github.io/ensae-reproductibilite-website/chapters/application.html) du cours
