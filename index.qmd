---
title: Mise en production des projets de data science
subtitle: |
    [Cours de 3e ann√©e √† l'ENSAE]{.blue2}<br>
    2025/2026
author:
    - Romain Avouac
    - Lino Galiana
# date:
slide-number: true
footer: |
  Bonnes pratiques pour la mise en production des projets de data science ([retour _homepage_](https://ensae-reproductibilite.github.io/)) [{{< fa brands github >}}](https://github.com/ensae-reproductibilite/)
# uncomment for French presentations:
lang: fr-FR
# for blind readers:
slide-tone: false
chalkboard: # press the B key to toggle chalkboard
  theme: whiteboard
# uncomment to use the multiplex mode:
#multiplex: true
format:
  # pick the light mode (onyxia-revealjs) or the dark mode (onyxia-dark-revealjs)
  onyxia-revealjs:
  #onyxia-dark-revealjs:
    incremental: true
    output-file: index.html
controls: true
css: custom.css
from: markdown+emoji
---

# Introduction

## Ressources associ√©es

:::: {.columns}

::: {.column width="50%"}
### Slides

{{< qrcode https://ensae-reproductibilite.github.io/slides/ qr1 width=400 height=400 >}}

:::

::: {.column width="50%"}
### Site web

{{< qrcode https://ensae-reproductibilite.github.io/website/ qr2 width=400 height=400 >}}

:::

::::




## Contexte {.nonincremental auto-animate=true}

![](https://minio.lab.sspcloud.fr/lgaliana/generative-art/mise-en-prod/slides-comic.jpg){fig-align="center"}

- [**Qui sommes-nous ?**]{.orange}


## Contexte {.nonincremental auto-animate=true}

![](https://minio.lab.sspcloud.fr/lgaliana/generative-art/mise-en-prod/slides-comic.jpg){fig-align="center"}


- [**Qui sommes-nous ?**]{.orange}
    - des [**data scientists**]{.blue2} de l'Insee
    - frustr√©s par l'[**approche**]{.blue2} souvent purement [**technique**]{.blue2} de la data science
    - convaincus que les [**bonnes pratiques de d√©veloppement**]{.blue2} valent √† √™tre enseign√©es

- {{< fa solid envelope >}} <romain.avouac@insee.fr>, <lino.galiana@insee.fr>

## Qu'est ce qu'un data scientist ?

![](img/sexiest-job.png){fig-align="center" height=250}

- Tendance √† la [**sp√©cialisation**]{.orange} : *data analyst*, *data engineer*, *ML Engineer*...

- R√¥le d'[**interface**]{.orange} entre m√©tier et √©quipes techniques
    - [**Comp√©tences mixtes**]{.blue2} : savoir m√©tier, mod√©lisation, IT

## La notion de mise en production

- [**Mettre en production**]{.orange} : faire [**vivre**]{.blue2} une application dans l'espace de ses [**utilisateurs**]{.blue2}
    - Notion simple mais mise en oeuvre compliqu√©e !

- [**D√©passer le stade de l'exp√©rimentation**]{.orange}
    - Comprendre les [**besoins**]{.blue2} des utilisateurs
    - [**Bonnes pratiques**]{.blue2} de d√©veloppement
    - Techniques informatiques d'[**industrialisation**]{.blue2}

## La notion de bonnes pratiques

- [**Origine**]{.blue2} : communaut√© des d√©veloppeurs logiciels

- [**Constats**]{.blue2} :
    - le [_"code est plus souvent lu qu'√©crit"_]{.green2} ([Guido Van Rossum](https://fr.wikipedia.org/wiki/Guido_van_Rossum))
    - la maintenance d'un code est tr√®s co√ªteuse

- [**Cons√©quence**]{.blue2} : un ensemble de [**r√®gles informelles**]{.orange}, conventionnellement accept√©es comme produisant des logiciels [**fiables**]{.orange}, [**√©volutifs**]{.orange} et [**maintenables**]{.orange}

## Pourquoi s'int√©resser aux bonnes pratiques ?

<br>

L'activit√© du *datascientist* tend √† se rapprocher de celle du d√©veloppeur :

- projets [**intenses en code**]{.blue2}

- [**projets collaboratifs**]{.blue2} et de grande envergure

- [**complexification**]{.blue2} des donn√©es et des [**infrastructures**]{.blue2}

- [**d√©ploiement**]{.blue2} d'applications pour valoriser les mod√®les

## Contenu du cours {.scrollable .smaller}

- [**Pr√©-requis**]{.orange}
    - Introduction au terminal `Linux` ([Linux 101](https://ensae-reproductibilite.github.io/website/chapters/linux-101.html))
    - [**Contr√¥le de version**]{.blue2} avec `Git` ([Git _refresher_](https://ensae-reproductibilite.github.io/website/chapters/git.html))

- [**Bonnes pratiques**]{.orange} de d√©veloppement
    - [**Travail collaboratif**]{.blue2} avec `Git`
    - [**Qualit√©**]{.blue2} du code
    - [**Structure**]{.blue2} des projets
    - Traitement des [**donn√©es volumineuses**]{.blue2}
    - Favoriser la [**portabilit√©**]{.blue2} d'une application

- [**Mise en production**]{.orange}
    - Introduction au format `YAML`
    - [**D√©ploiement**]{.blue2}
    - [**MLOps**]{.blue2}

## Site web du cours

- [https://ensae-reproductibilite.github.io/website/](https://ensae-reproductibilite.github.io/website/)

- Tout le contenu du cours est en [***open-source***]{.orange}
    - [GitHub](https://github.com/orgs/ensae-reproductibilite/repositories) {{< fa brands github >}}
    - *Pull Requests* -> bonus {{< fa comment-dollar >}}

## Modalit√©s p√©dagogiques

- Apprentissage par la pratique
    - [Application](https://ensae-reproductibilite.github.io/website/chapters/application.html) : industrialisation d'un projet de ML

- Langage : `Python` {{< fa brands python >}}
    - Langage [**dominant**]{.blue2} dans le monde de la donn√©e
    - Les principes pr√©sent√©s sont [**agnostiques**]{.blue2} au langage

- Environnement d'ex√©cution : [SSP Cloud](https://datalab.sspcloud.fr/)
    - Environnement de d√©veloppement [**normalis√©**]{.blue2}
    - V√©ritable environnement de [**production**]{.blue2}
    - Acquisition des [**bonnes pratiques**]{.blue2}

## Evaluation

- [**Objectif**]{.orange} : mise en pratique [**r√©aliste**]{.orange} des notions √©tudi√©es
    - [**Probl√©matique m√©tier**]{.blue2}
    - [**Donn√©es r√©elles**]{.blue2}

- Evaluation en [**deux parties**]{.orange} :
    - [**En groupe**]{.blue2} : [**projet**]{.blue2} √† construire selon 4 "parcours"
    - [**Individuel**]{.blue2} : [**revue de code**]{.blue2} d'un autre projet






# Partie :one: : bonnes pratiques de d√©veloppement

## Plan de la partie

:one: [**Travail collaboratif**]{.blue2} avec `Git`

:two: [**Qualit√©**]{.blue2} du code

:three: [**Structure**]{.blue2} des projets

:four: Traitement des [**donn√©es volumineuses**]{.blue2}

:five: Favoriser la [**portabilit√©**]{.blue2} d'une application





# :one: Le travail collaboratif avec `Git`

## Pourquoi utiliser Git ?

![Source : [ThinkR](https://thinkr.fr/travailler-avec-git-via-rstudio-et-versionner-son-code/)](img/timeline.png){fig-align="center" height=475}

## Concepts essentiels

![Source : [fabacademy.org](http://fabacademy.org/2021/labs/bhubaneswar/students/deepak-chaudhry/ia_PPFP.html)](img/gitallinone.png){height="400" fig-align="center"}

## Bonnes pratiques {auto-animate=true .smaller}

__Que versionne-t-on ?__

- Essentiellement du [**code source**]{.orange}
- [__Pas d'outputs__]{.orange} (fichiers `.html`, `.pdf`, mod√®les...)
- [__Pas de donn√©es__]{.orange}, d'informations locales ou sensibles

. . .

:::{.callout-note}

Pour d√©finir des r√®gles qui √©vitent de committer tel ou tel fichier, on utilise
un fichier nomm√© __`.gitignore`__.

Si on m√©lange du code et des √©l√©ments
annexes (_output_, donn√©es...) dans un m√™me dossier, il [__faut consacrer du temps √† ce fichier__]{.orange}.

N'h√©sitez pas √† y ajouter des r√®gles conservatrices (par exemple `*.csv`, `*.parquet`).
:::

## Bonnes pratiques {auto-animate=true .smaller}

__Format des commits__

::: {layout="[40,60]"}

- [**Fr√©quence**]{.orange}
    - Aussi souvent que possible
    - Le lot de modifications doit "faire sens"
- [**Messages**]{.orange}
    - Courts et informatifs (comme un titre de mail)
    - D√©crire [**le pourquoi plut√¥t que le comment**]{.orange} dans le texte

![](img/titre-commit.png)

:::

## Outils pour le travail collaboratif

- L'√©co-syst√®me `Git` [**facilite** le travail collaboratif]{.blue2}
    - `Git` {{< fa brands git-alt >}} : mod√®le des [__branches__]{.orange}
    - `GitHub` {{< fa brands github >}} / `GitLab` {{< fa brands gitlab >}} : [**Issues**, **Pull Requests**, **Forks**]{.orange}

## Le mod√®le des branches

::: {layout="[[-1], [1], [-1]]"}
![Source : [lutece.paris.fr](https://lutece.paris.fr/support/jsp/site/Portal.jsp?page=wiki&view=page&page_name=git&language=fr)](img/branches.png){fig-align="center" height=350}
:::

## Les outils de contribution

- [***Issue***]{.orange} : soumettre un [**probl√®me**]{.blue2} ou une [**suggestion**]{.blue2} aux d√©veloppeurs d'un projet

- [***Pull Request***]{.orange} : proposer aux d√©veloppeurs d'un projet d'[**int√©grer des modifications**]{.blue2}

- [***Fork***]{.orange} : faire la [**copie**]{.blue2} d'un projet existant dans son espace personnel
    - Indispensable pour faire une *pull request* √† un d√©p√¥t sur lequel on n'a pas les droits

## Une organisation courante : le *GitHub flow*

![](img/ghflow.png)

Description plus d√©taill√©e : [ici](https://docs.github.com/en/get-started/quickstart/github-flow)







# :two: Qualit√© du code

## Enjeux

- D'une vision utilitariste du code √† une vision du code comme [**outil de communication**]{.orange}

- Favoriser la [**lisibilit√©**]{.orange} et la [**maintenabilit√©**]{.orange}

- Faciliter la [**r√©utilisation**]{.orange}

## Principes g√©n√©raux

- Adopter les [**standards communautaires**]{.orange}

- Utiliser des [**fonctions**]{.orange}

- [**(Auto-)documenter**]{.orange} son code

## :one: Standards communautaires

> *"Good coding style is like correct punctuation: you can manage without it, butitsuremakesthingseasiertoread"*
>
> [Tidyverse Style Guide (R)](https://style.tidyverse.org/)

- [**Python**]{.blue2} : [PEP8](https://peps.python.org/pep-0008/), [PEP 257](https://peps.python.org/pep-0257/)
    - Des r√®gles *opinionated*, mais [**conventionnelles**]{.blue2}

- La [**coh√©rence intra-projet**]{.orange} doit toujours primer

## :one: Standards communautaires - Outils {.smaller}

- [**Linters**]{.blue2} : diagnostic de qualit√© du code
    - [Pylint](https://github.com/PyCQA/pylint)

- [**Formatters**]{.blue2} : application automatique des standards
    - [Black](https://github.com/psf/black)

. . .

::: {.callout-tip}
- [Exemples d‚Äôerreurs rep√©r√©es]{.blue2} par un _linter_ :
    + lignes de code trop longues ou mal indent√©es, parenth√®ses non √©quilibr√©es, noms de fonctions mal construits‚Ä¶
- [Exemples d‚Äôerreurs __non__ rep√©r√©es]{.blue2} par un _linter_ :
    + fonctions mal utilis√©es, arguments mal sp√©cifi√©s, structure du code incoh√©rente, code insuffisamment document√©‚Ä¶
:::

## :two: Utiliser des fonctions {.smaller}

::: {.callout-important}
## R√®gle d'or

Il faut utiliser une [**fonction**]{.red2} d√®s qu'on utilise une m√™me
portion de code plus de deux fois ([**_don't repeat yourself_ (DRY)**]{.red2})
:::

- [**Limite les risques d'erreurs**]{.orange} li√©s aux copier/coller
- Rend le code [**plus lisible**]{.orange} et [**plus compact**]{.orange}
- [**Un seul endroit**]{.orange} du code √† modifier lorsqu'on souhaite modifier le traitement
- Facilite la [**r√©utilisation**]{.orange} et la [**documentation**]{.orange} du code !

. . .

::: {.callout-tip}
## R√®gles pour √©crire des fonctions **pertinentes**

- Une t√¢che = une fonction
- Une t√¢che complexe = un encha√Ænement de fonctions r√©alisant chacune une t√¢che simple
- Limiter l'utilisation de variables globales.

:::

## :three: Documenter son code

- Documenter le [__pourquoi__]{.orange} plut√¥t que le [__comment__]{.orange}

- Privil√©gier l'[**auto-documentation**]{.orange} via des nommages pertinents

. . .

::: {.callout-tip}
## Comment bien documenter un script ?

- [**Minimum**]{.orange} üö¶ : d√©crire ce que le code fait au d√©but du script
- [**Bien**]{.orange} üëç : commenter les parties "d√©licates" du code
- [**Id√©al**]{.orange} üí™ : documenter ses fonctions avec des *docstrings*
:::





# :three: Structure des projets

## Enjeux

- Favoriser la [**lisibilit√©**]{.orange} et la [**maintenabilit√©**]{.orange}

- Enjeux sp√©cifiques √† la data science
    - [**Exp√©rimentation**]{.blue2}
    - [**Non-lin√©arit√©**]{.blue2}
    - [**Reproductibilit√©**]{.blue2}

## Principes g√©n√©raux

- Favoriser une [**structure modulaire**]{.blue2} selon l'√©tat du projet
    - [**Exploration**]{.orange} : travail √† partir de [**notebooks**]{.blue2}
    - [**Industrialisation**]{.orange} : adopter une structure type [**package**]{.blue2}

- Adopter les [**standards communautaires**]{.orange}

- [**(Auto-)documenter**]{.orange} son projet

## :one: Phase d'exploration : *notebooks*

- [**Avantages**]{.orange}
  - [**Interactivit√©**]{.blue2} : id√©al pour l'exp√©rimentation
  - [**Communication**]{.blue2} : diffusion de r√©sultats sous forme ex√©cutable

- [**Inconv√©nients**]{.orange}
  - [**Reproductibilit√©**]{.blue2} g√©n√©ralement limit√©e
  - Pas adapt√©s pour l'[**automatisation**]{.blue2}
  - Mal g√©r√©s par le [**contr√¥le de version**]{.blue2}

## :two: Industrialisation : structure modulaire

- [**Premier niveau**]{.orange} : structuration du [**code**]{.orange}

- Adopter une structure type [**package**]{.orange}
  - Des [**fonctions**]{.blue2} rang√©es dans des [**modules**]{.blue2}
  - Un script principal (`main`) [**orchestre**]{.blue2} les traitements
  - Utilisation de [**chemins relatifs**]{.blue2} uniquement

## :two: Industrialisation : structure modulaire

- [**Deuxi√®me niveau**]{.orange} : structuration du [**projet**]{.orange}

. . .

![](img/project-modularity.png){fig-align="center" height=350}

## :three: Adopter les standards communautaires

- [**Templates**]{.orange} de projets : [**Cookiecutters**]{.blue2}
    - [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/)
    - [Cookiecutter Python Package](https://py-pkgs.org/03-how-to-package-a-python#creating-a-package-structure)

- La [**coh√©rence intra-projet**]{.orange} doit toujours primer

## :four: Documenter son projet

- Favoriser l'[**auto-documentation**]{.orange} via des nommages pertinents

## L'auto-documentation : illustration

```
‚îú‚îÄ‚îÄ report.ipynb
‚îú‚îÄ‚îÄ correlation.png
‚îú‚îÄ‚îÄ data.csv
‚îú‚îÄ‚îÄ data2.csv
‚îú‚îÄ‚îÄ fig1.png
‚îú‚îÄ‚îÄ figure 2 (copy).png
‚îú‚îÄ‚îÄ report.pdf
‚îú‚îÄ‚îÄ partial data.csv
‚îú‚îÄ‚îÄ script.py
‚îî‚îÄ‚îÄ script_final.py
```

- Difficile de rentrer dans le projet...
    - Tout au [**m√™me niveau**]{.blue2}
    - Titres [**non informatifs**]{.blue2}

## L'auto-documentation : illustration

```
‚îú‚îÄ‚îÄ data
‚îÇ   ‚îú‚îÄ‚îÄ raw
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data2.csv
‚îÇ   ‚îî‚îÄ‚îÄ interim
‚îÇ       ‚îî‚îÄ‚îÄ partial data.csv
‚îú‚îÄ‚îÄ notebooks
‚îÇ   ‚îî‚îÄ‚îÄ report.ipynb
‚îú‚îÄ‚îÄ src
|   ‚îú‚îÄ‚îÄ script.py
‚îÇ   ‚îî‚îÄ‚îÄ script_final.py
‚îî‚îÄ‚îÄ reports
    ‚îú‚îÄ‚îÄ report.pdf
    ‚îî‚îÄ‚îÄ figures
        ‚îú‚îÄ‚îÄ fig1.png
        ‚îú‚îÄ‚îÄ figure 2 (copy).png
        ‚îú‚îÄ‚îÄ figure10.png
        ‚îî‚îÄ‚îÄ correlation.png
```

- Une structure d√©j√† plus lisible !
    - Les titres restent [**non informatifs**]{.blue2}

## L'auto-documentation : illustration

```
‚îú‚îÄ‚îÄ data
‚îÇ   ‚îú‚îÄ‚îÄ raw
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dpe_logement_202103.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dpe_logement_202003.csv
‚îÇ   ‚îî‚îÄ‚îÄ interim
‚îÇ       ‚îî‚îÄ‚îÄ dpe_logement_merged_preprocessed.csv
‚îú‚îÄ‚îÄ notebooks
‚îÇ   ‚îî‚îÄ‚îÄ report.ipynb
‚îú‚îÄ‚îÄ src
|   ‚îú‚îÄ‚îÄ main.R
|   ‚îú‚îÄ‚îÄ preprocessing.R
‚îÇ   ‚îî‚îÄ‚îÄ generate_plots.R
‚îî‚îÄ‚îÄ reports
    ‚îú‚îÄ‚îÄ report.pdf
    ‚îî‚îÄ‚îÄ figures
        ‚îú‚îÄ‚îÄ histogram_energy_diagnostic.png
        ‚îú‚îÄ‚îÄ barplot_consumption_pcs.png
        ‚îú‚îÄ‚îÄ correlation_matrix.png
        ‚îî‚îÄ‚îÄ correlation.png
```

- Une structure [**auto-document√©e**]{.blue2}
    - On comprend le projet sans m√™me lire le code

## :four: Documenter son projet

- Favoriser l'[**auto-documentation**]{.orange} via des nommages pertinents

- Inclure un fichier `README.md` √† la racine du projet
    - [**Carte d'identit√©**]{.blue2} et [**vitrine**]{.blue2} du projet
    - Pr√©sente le [**contexte**]{.blue2} et le [**fonctionnement**]{.blue2} du projet

- Si [**open-source**]{.orange} : inclure une [licence](https://docs.github.com/fr/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/licensing-a-repository)






# Application

## Bonnes pratiques de d√©veloppement

- Consignes sur le [site du cours](https://ensae-reproductibilite.github.io/website/chapters/application.html)
    - Partie :zero: : initialisation de l'environnement et du projet
    - Partie :one: : qualit√© du code
    - Partie :two: : adoption d'une structure modulaire






# :four: Traitement des donn√©es volumineuses

## "The obligatory intro slide"

![Source : [motherduck.com](https://motherduck.com/blog/big-data-is-dead/)](img/intro-big-data.png){fig-align="center" height=400}

## Enjeux

- Tendance √† la [**massification**]{.orange} des donn√©es

![Source : [AI with Python](https://www.packtpub.com/product/artificial-intelligence-with-python-second-edition/9781839219535)](img/vvv.png){fig-align="center" height=350 .fragment}

## Enjeux

- N√©cessit√© de bien distinguer :
    - [***Storage***]{.blue2} : qu'est-ce que l'on stocke et comment ?
    - [***Compute***]{.blue2} : qu'est-ce que l'on calcule et o√π ?

- Evolutions des [**infrastructures de donn√©es**]{.orange} :
    - [**Bases de donn√©es**]{.blue2} : couplage fort, scalabilit√© verticale
    - [**Infrastructures *big data***]{.blue2} : couplage fort, scalabilit√© horizontale
    - [**Infrastructures *cloud***]{.blue2} : couplage faible, scalabilit√© hybride

## :one: A l'origine : les bases de donn√©es

- Historiquement : stockage dans des [**bases de donn√©es**]{.orange}

- 80's : essor des [bases de donn√©es relationnelles](https://fr.wikipedia.org/wiki/Base_de_donn%C3%A9es_relationnelle)
    - Mod√®le de la [***data warehouse***]{.orange}

![Source : [corporatefinanceinstitute.com](https://corporatefinanceinstitute.com/resources/business-intelligence/data-warehousing/)](img/data-warehouse.png){height="300" fig-align="center" .fragment}

## :one: Limites des *data warehouses*

- Peu adapt√©es aux [**donn√©es *big data***]{.orange} 
    - Limit√©es aux [**donn√©es structur√©es**]{.blue2}
    - N√©cessiter de fixer un [**sch√©ma a priori**]{.blue2}
    - Passage √† l'√©chelle co√ªteux : [**scalabilit√© verticale**]{.blue2}

![Source : [https://dev.to](https://dev.to/yugabyte/horizontal-scaling-vs-vertical-scaling-for-sql-what-s-the-difference-kn2)](img/vertical-scaling-pgsql.png){height="250" fig-align="center" .fragment}

## :two: L'arriv√©e du *data lake* (fin 2000's) {.scrollable}

- Un stockage [**peu co√ªteux**]{.orange} fait pour des [**donn√©es**]{.orange}
  - [**Volumineuses**]{.blue2}
  - [**Brutes**]{.blue2}
  - Sans [**structure d√©finie a priori**]{.blue2}

![Source : [qlik.com](https://www.qlik.com/us/data-lake)](img/datalake.png){height="300" fig-align="center" .fragment}

## :two: Infrastructures *big data* {.scrollable}

- Fin 2000's : une architecture de r√©f√©rence ([Hadoop](https://fr.wikipedia.org/wiki/Hadoop))
    - Une [***data lake***]{.blue2} avec du [**stockage distribu√©**]{.blue2} (HDFS)
    - Des [**frameworks de calcul distribu√©**]{.blue2} ([MapReduce](https://fr.wikipedia.org/wiki/MapReduce), [Spark](https://fr.wikipedia.org/wiki/Apache_Spark))

![Source : [glennklockwood.com](https://www.glennklockwood.com/data-intensive/hadoop/overview.html)](img/mapreduce-hdfs.png){fig-align="center" height="350" .fragment}

## :three: "Big Data is dead" ?

- 2010's : d√©clin de popularit√© des infrastructures Hadoop
    - Limite : [**co-localisation**]{.blue2} du stockage et du calcul

- Jordan Tigani : [Big Data is dead](https://motherduck.com/blog/big-data-is-dead/)
    - Besoins de [***storage***]{.blue2} >> besoins de [***compute***]{.blue2}

![](img/tigani-compute-storage.png){height="330" fig-align="center" .fragment}

## :three: Infrastructures *cloud*

- Fin 2010's : [**les technologies *cloud***]{.orange} permettent l'√©mergence d'architectures [**faiblement coupl√©es**]{.orange}
    - [***Storage***]{.blue2} : [***data lake***]{.blue2} bas√© sur du [**stockage objet**]{.blue2}
    - [***Compute***]{.blue2} : des environnements de traitement √©lastiques aux besoins ([**conteneurs**]{.blue2})

![](img/environment_cloud.png){height="300" fig-align="center" .fragment}

## :three: La fronti√®re du *big data* se d√©cale

- [**Innovations mat√©rielles**]{.orange} (serveurs, CPUs, RAM)

- [**Formats de donn√©es**]{.orange} plus efficients ([**Parquet**]{.orange})

- Des outils de [**traitement *larger-than-memory***]{.orange}

![](img/tigani-big-data-frontier.png){height="330" fig-align="center" .fragment}

## :three: Le format `CSV`

- Le format usuel pour les [**donn√©es tabulaires**]{.orange} est le `CSV`
    - Facilement [**lisible**]{.blue2} 
    - [**Non-compress√©**]{.blue2} : espace disque √©lev√©
    - [**Orient√© ligne**]{.blue2} : mal adapt√© aux traitements analytiques

![](img/columnar-storage.png){height="300" fig-align="center" .fragment}

## :three: Le format `Parquet` : propri√©t√©s

- [**Orient√© colonne**]{.orange}
  - Adapt√© aux [**traitements analytiques**]{.blue2}
  - Con√ßu pour √™tre √©crit une fois mais lu fr√©quemment

- [**Optimis√©**]{.orange}
  - [**Compression**]{.blue2} (jusqu'√† 87 % moins d'espace qu'un CSV)
  - [**Lecture**]{.blue2} du fichier (jusqu'√† 34x plus rapide qu'un CSV)

- [**Interop√©rable**]{.orange}
    - Gestion native des [**m√©ta-donn√©es**]{.blue2}

## :three: `Parquet` : partitionnement

- [**Division en blocs**]{.orange} des donn√©es selon un [**crit√®re**]{.orange}
  - [**Optimise la lecture**]{.blue2} pour certaines requ√™tes

![](img/parquet-partition.png){height="400" fig-align="center" .fragment}

## :three: Traitement *in-memory*

- `Parquet` ne r√©sout pas tout
  - L'espace disque est optimis√©
  - Les donn√©es d√©compress√©es doivent [**passer en RAM**]{.blue2}

- Avec un *framework* traditionnel de [**calcul en m√©moire**]{.orange} (`Pandas`, `dplyr` en `R`, etc.)
    - [**Gain en lecture**]{.blue2} gr√¢ce √† la compression `Parquet`
    - Oblig√© de charger [**l'ensemble du fichier en m√©moire**]{.blue2}
    - [**Perte de l'avantage de la structure en colonne**]{.blue2}

## :three: Traitement *larger-than-memory*

- Calcul [***larger than memory* optimis√©**]{.blue2}
    - [Arrow](https://arrow.apache.org/overview/) : orientation fichier (`Parquet`)
    - [DuckDB](https://duckdb.org/) : orientation base de donn√©es (`SQL`)

- Principes communs : 
    - [**Orientation colonne**]{.blue2} : synergie avec `Parquet`
    - [**Lazy evaluation**]{.blue2} : tr√®s efficient en donn√©es

![](img/parquet-read-columns.png){height="200" fig-align="center" .fragment}

## :three: `DuckDB` : un connecteur interop√©rable entre sources de donn√©es

![](img/duckdb-intero.png){height="500" fig-align="center" .fragment}

## R√©sum√© : pour traiter la volum√©trie

- Choisir une [**infrastructure**]{.orange} adapt√©e aux besoins
    - Les [**technologies *cloud***]{.blue2} offrent un tr√®s bon compromis co√ªt / flexibilit√©

- Utiliser un [**format**]{.orange} de donn√©es adapt√© (`Parquet`)

- Utiliser des [**outils**]{.orange} de traitement adapt√©s
  - Suffisant la plupart du temps : [**calcul *larger than memory* optimis√©**]{.blue2} (`DuckDB`)
  - Si volum√©trie massive : [**calcul distribu√©**]{.blue2} (`Spark`)

# :five: Portabilit√©

## "It works... on my machine" {.scrollable}

- On a construit un projet [**lisible**]{.orange}, [**structur√©**]{.orange} et [**versionn√©**]{.orange}

- Peut-on [**partager**]{.orange} notre projet ?
    - En th√©orie, oui !
    - En pratique, c'est toujours plus compliqu√©...

![Source : [simply-the-test.blogspot.com](https://simply-the-test.blogspot.com/2010/05/it-works-on-my-machine.html)](img/IWOMM.jpg){fig-align="center" height=350 .fragment}

## Pourquoi se pr√©occuper de portabilit√© ?

- Consid√©rons un [***workflow* standard**]{.orange} de *data science*
    - Installer une distribution de `Python` sur son poste
    - D√©velopper un projet en installant les packages n√©cessaires
    - Passer au projet suivant et ainsi de suite

- Quels [**probl√®mes**]{.orange} peuvent se poser ?

## Pourquoi se pr√©occuper de portabilit√© ?

- [**Conflits de version**]{.orange} : diff√©rents projets peuvent requ√©rir des versions diff√©rentes d'un m√™me *package*

- [**Version de `Python` fixe**]{.orange}, celle de l'installation syst√®me

- [**Reproductibilit√© limit√©e**]{.orange} : difficile de dire quel projet n√©cessite quel package

- [**Portabilit√© limit√©e**]{.orange} : difficile de fixer dans un fichier les d√©pendances sp√©cifiques √† un projet

## Le crit√®re de la portabilit√©

- Un code n'est pas auto-suffisant, il contient en g√©n√©ral de nombreuses [**adh√©rences**]{.orange}
    - Un [**langage de programmation**]{.blue2} et sa [**version**]{.blue2}
    - Des [**d√©pendances**]{.blue2}
    - Des [**librairies syst√®me**]{.blue2}

- [**Portabilit√©**]{.orange} : capacit√© d'un code √† s'ex√©cuter dans un environnement diff√©rent que celui de d√©veloppement
    - Enjeu central de la [**mise en production**]{.blue2} !

## Comment favoriser la portabilit√© ?

- Constuire des [**"bulles" plus ou moins isol√©es**]{.orange} autour de son projet afin de [***packager* l'environnement**]{.orange} n√©cessaire

- Des outils d√©di√©s :
    - Les [**environnements virtuels**]{.blue2} : tr√®s simples √† prendre en main, [**portabilit√© moyenne**]{.blue2}
    - Les [**conteneurs**]{.blue2} : plus complexes d'utilisation, [**portabilit√© maximale**]{.blue2}

## Environnements virtuels : fonctionnement {.scrollable}

- [**Dossier "auto-suffisant"**]{.orange} qui :
    - contient un [**intepr√©teur**]{.blue2} `Python` et des [**packages**]{.blue2}
    - est [**isol√©**]{.orange} des autres environnements existants

![Source : [dataquest.io](https://www.dataquest.io/blog/a-complete-guide-to-python-virtual-environments/)](img/venv.png){fig-align="center" height=350 .fragment}

## Environnements virtuels : impl√©mentations

-  [**Impl√©mentation standard**]{.orange} de `Python` : [venv](https://docs.python.org/fr/3/library/venv.html)
    - Il en existe bien d'autres (`virtualenv`, `pipenv`, etc.)

- Tr√®s li√© au [**mode d'installation des *packages***]{.orange}
    - Python "standard" : `venv` + `pip`
    - Limites :
        - Lenteur de la [**r√©solution des d√©pendances**]{.blue2}
        - D√©pendance √† la version syst√®me de `Python`

- [**Une impl√©mentation qui monte**]{.orange} tr√®s (tr√®s) vite : [uv](https://docs.astral.sh/uv/)

## `uv` : un outil pour les gouverner tous

![Source : [alpopkes.com](https://alpopkes.com/posts/python/packaging_tools/?ref=blog.ippon.fr/)](img/uv-venn.png){fig-align="center" height=500 .fragment}

## `uv` : utilisation

- [**Initialiser**]{.orange} un projet : `uv init <nom_du_projet>`
    - G√©n√®re une [**structure de projet**]{.blue2}

- [**Installer**]{.orange} un package : `uv add scikit-learn`
    - G√©n√®re automatiquement un [**environnement virtuel**]{.blue2} (`venv`)

- [**Ex√©cuter**]{.orange} un script : `uv run script.py`
    - Le script est ex√©cut√© avec l'interp√©teur `Python` [**de l'environnement virtuel**]{.blue2}

## Sp√©cifier l'environnement du projet

- D√©velopper dans un [**environnement virtuel**]{.orange} est une bonne pratique

- Favorise la [**reproductibilit√©**]{.orange}
    - A chaque installation d'un *package*, `uv` met √† jour le fichier `uv.lock` qui [**sp√©cifie toutes les d√©pendances**]{.blue2}
    - `uv sync` ->  [**recr√©e l'environnement complet**]{.blue2}

- Favorise la [**portabilit√©**]{.orange}
    - A chaque installation d'un *package*, `uv` maj le fichier `pyproject.yaml` qui [**sp√©cifie les *packages* n√©cessaires**]{.blue2}
    - A *commit* sur `Git` pour [**distribuer la "recette" de l'environnement**]{.blue2}

## Faire √©voluer les versions

- [**Arbitrage**]{.orange} √† trouver entre :
    - [**Reproductibilit√©**]{.blue2} : [**sp√©cifier**]{.blue2} finement les versions
    - [**Fonctionnalit√©s et s√©curit√©**]{.blue2} : faire [**√©voluer**]{.blue2} les versions

## Environnements virtuels : limites

- [**Limit√©s au langage**]{.orange}  de programmation et ses *packages* :
    - Pas de gestion des [**librairies syst√®me**]{.blue2} qui d√©pendent du syst√®me d'exploitation
    - Non adapt√©s √† des [**projets multi-langages**]{.blue2}

- Les environnements virtuels [**facilitent la portabilit√©, mais ne suffisent pas √† la garantir**]{.orange} 

## Le *gold-standard* de la portabilit√©

- Au lieu de distribuer la [**recette**]{.orange} pour recr√©er la bonne machine, peut-on [**distribuer directement la bonne machine**]{.orange} ?
    - Id√©e 1 : distribuer des [**machines physiques**]{.blue2} : complexe...
    - Id√©e 2 : distribuer des [**machines virtuelles**]{.blue2} : possible mais co√ªteux

- Les [**conteneurs**]{.orange} offrent le compromis id√©al
    - [**Isolation compl√®te**]{.blue2} de l'environnement
    - Relativement [**l√©gers**]{.blue2} et donc facilement redistribuables

## Conteneurs vs. machines virtuelles

![Source : [docker.com](https://www.docker.com/resources/what-container/)](img/docker-vm.png)

## Conteneurs : impl√©mentations

- Plusieurs impl√©mentations des conteneurs
    - [**`Docker`**]{.blue2} est largement pr√©dominant

. . .

![](img/docker.png){fig-align="center" height=200}

## `Docker` : installation

- `Docker` : outil en ligne de commande (CLI)
    - [Instructions](https://docs.docker.com/get-docker/) selon le syst√®me d'exploitation
    - Environnement "bac √† sable" : [Play with Docker](https://labs.play-with-docker.com/)

. . .

![](img/playwithdocker.png){fig-align="center" height=350}

## Le `Dockerfile`

- Exemple : [conteneurisation d'une API avec FastAPI](https://fastapi.tiangolo.com/deployment/docker/)

. . .

```Dockerfile  {.scrollable}
FROM ubuntu:20.04

RUN apt-get update -y && \
    apt-get install -y python3-pip python3-dev

WORKDIR /app

COPY requirements.txt /app/requirements.txt
RUN pip install -r requirements.txt

COPY . /app

ENV FLASK_APP="my-app.py"
EXPOSE 5000

CMD ["flask", "run", "--host=0.0.0.0"]
```

## `Docker` : fonctionnement

![Source : [k21academy.com](https://k21academy.com/docker-kubernetes/docker-and-kubernetes/)](img/docker-workflow.png){fig-align="center"}

## `Docker` en pratique

- Pr√©sentation d√©taill√©e sur la [page du cours](https://ensae-reproductibilite.github.io/website/chapters/portability.html#les-conteneurs)
    - [**Concepts**]{.blue2} (*caching*, *buildtime/runtime*)
    - [**Commandes**]{.blue2} essentielles
    - [**Application**]{.blue2} √† un exemple concret






# Application

## Portabilit√© du projet

- Consignes sur le [site du cours](https://ensae-reproductibilite.github.io/website/chapters/application.html)
    - Partie :three: : construction d‚Äôun projet [**portable**]{.orange} et [**reproductible**]{.orange}
        - Construire un [**environnement virtuel**]{.blue2} pour le projet
        - [**Conteneuriser**]{.blue2} l'application avec `Docker`







# Partie :two: : mise en production

## Le "mur de la production"

- La majorit√© des projets "*data-driven*" [**ne d√©livrent pas de valeur**]{.blue2} ([1](https://sloanreview.mit.edu/projects/expanding-ais-impact-with-organizational-learning/), [2](https://hdsr.mitpress.mit.edu/pub/2fu65ujf/release/6), [3](https://www.researchgate.net/publication/346647451_Beyond_the_Hype_Why_Do_Data-Driven_Projects_Fail))

- Comment [**d√©passer le stade de l'exp√©rimentation**]{.orange} ?

## Mise en production

- [**Mettre en production**]{.orange} : faire [**vivre**]{.blue2} une application dans l'espace de ses [**utilisateurs**]{.blue2}
    - [**Servir**]{.orange} : [**d√©ployer**]{.blue2} l'application dans un [**format pertinent**]{.blue2} aupr√®s de ses utilisateurs potentiels
    - [**Faire vivre**]{.orange} : g√©rer le [**cycle de vie**]{.blue2} et favoriser l'[**am√©lioration continue**]{.blue2}

- [**Multiples dimensions**]{.orange} : connaissance m√©tier, organisation, infrastructure, outils techniques..

## Favoriser la continuit√©

![Source : [ibm.com](https://public.dhe.ibm.com/software/data/sw-library/analytics/data-science-lifecycle/#model-implementation)](img/exploration-production.png){fig-align="center"}

- [**Comment faire ?**]{.orange}
    - Application des [**bonnes pratiques**]{.blue2} de d√©veloppement
    - Besoin de [**nouveaux concepts et outils**]{.blue2} : [DataOps](https://dataopsmanifesto.org/fr/)

## Le DataOps

- Origine : mouvement [DevOps](https://fr.wikipedia.org/wiki/Devops)

. . .

![Source : [syloe.com](https://www.syloe.com/expert-devops-automatisation-deploiements/)](img/devops.png){fig-align="center" height=300}

- [**DataOps**]{.orange} : construction de [**pipelines de donn√©es**]{.blue2}

- [**MLOps**]{.orange} : d√©ploiement et maintenance de [**mod√®les de ML**]{.blue2}

## Plan de la partie

:six: Introduction au format [**YAML**]{.blue2}

:seven: [**D√©ploiement**]{.blue2}

:eight: [**MLOps**]{.blue2}






# :six: Introduction au format `YAML`

## Qu'est-ce que le format `YAML` ?

- [*YAML Ain't Markup Language*](https://yaml.org/)
    - Langage de [**s√©rialisation**]{.blue2} de donn√©es
    - Structure [**expressive**]{.blue2} mais [**lisible**]{.blue2}

. . .

```yaml
---
source: ambient-it.net
domain:
 - devops
tutorial:
  - yaml:
      name: YAML Ain't Markup Language
      born: 2001
  - json:
      name: JavaScript Object Notation
      born: 2001
  - xml:
      name: Extensible Markup Language
      born: 1996
---
```

## Pourquoi s'int√©resser au `YAML` ?

- Outil standard pour les fichiers de [**configuration**]{.orange}
    - [*The rise of the YAML engineer*](https://ep2024.europython.eu/session/the-rise-of-the-yaml-engineer/)

- Simplicit√© et puissance du [**paradigme d√©claratif**]{.orange}
    - On d√©crit l'[**√©tat final souhait√©**]{.blue2}
    - L'impl√©mentation est laiss√©e au [**moteur sous-jacent**]{.blue2}

. . .

```yaml
kind: Pod
metadata:
  name: my-api-pod
spec:
  containers:
  - name: api
    image: my_dh_account/my_fast_api:0.0.1
    env:
    - name: MODEL
      value: deepseek-ai/DeepSeek-R1
```

## `YAML` vs. `JSON`

- `YAML` est un [**superset**]{.orange} de `JSON`
    - Tout fichier `JSON` valide est un fichier `YAML` valide

- Structure bas√©e sur l'[**indentation**]{.orange}
    - Favorise la [**lisibilit√©**]{.blue2}
    - Plus pr√¥ne aux [**erreurs**]{.blue2}

. . .

:::{layout-ncol="2"}

```yaml
user:
  name: Alice
  age: 30
```

```json
{
  "user": {
    "name": "Alice",
    "age": 30
  }
}
```

:::

- Convertisseurs : [yaml-to-json](https://jsonformatter.org/yaml-to-json), [json-to-yaml](https://jsonformatter.org/json-to-yaml)

## Caract√©ristiques d'un fichier `YAML`

- Extension : `.yaml` ou `.yml`

- Structure [**hi√©rarchique**]{.orange} bas√©e sur des [**paires cl√©-valeur**]{.orange}

- Diff√©rents [**types**]{.blue2} √† disposition (num√©riques, *strings*, bool√©ens, listes)

. . .

```yaml
kind: Pod
metadata:
  name: my-api-pod
spec:
  containers:
  - name: api
    image: my_dh_account/my_fast_api:0.0.1
    env:
    - name: MODEL
      value: deepseek-ai/DeepSeek-R1
    - name: DEBUG
      value: true
    ports:
    - containerPort: 8000
```

## Validation et erreurs fr√©quentes

- Principale erreur : mauvaise [**indentation**]{.orange}
    - Utiliser [**2 espaces**]{.blue2} (pas de tabulation!)

- Outils de [**validation**]{.orange} :
    - [**Support natif**]{.blue2} dans la plupart des IDE
    - [***Linters***]{.blue2} : [YAMLlint](https://yamllint.com)

## `YAML` et l'approche `GitOps`

- Le [**YAML**]{.orange} est le langage privil√©gi√© de l'[**approche GitOps**]{.orange}
    - Les manifestes sont [**d√©clar√©s**]{.blue2} en `YAML` (paradigme [**infrastructure as code**]{.blue2})
    - Les manifestes sont [**stock√©s**]{.blue2} sur un d√©p√¥t `Git` (approche [**GitOps**]{.blue2})

- Cette approche a de nombreux avantages :
    - [**Reproductibilit√©**]{.blue2}
    - [**Tra√ßabilit√©**]{.blue2}
    - [**Automatisation**]{.blue2}







# :seven: D√©ploiement

## Un sujet large

- Les [**questions essentielles**]{.orange} √† se poser :
    - Quel est le [**format**]{.blue2} adapt√© pour [**valoriser**]{.blue2} le projet ?
    - Quelle [**infrastructure de production**]{.blue2} ?
    - Comment [**automatiser**]{.blue2} le processus de d√©ploiement ?
    - Comment [**suivre**]{.blue2} l'application en production ?

- De [**nombreuses choix possibles**]{.orange}
    - Pr√©sentation des [**concepts et outils standards**]{.blue2}

## Formats de valorisation

- [**Crit√®res**]{.orange} √† prendre en compte :
    - Quels sont les [**utilisateurs**]{.blue2} potentiels ?
    - Quels sont leurs [**besoins**]{.blue2} ?

- [**Exemple**]{.orange} : mise √† disposition d'un [**LLM**]{.orange}

. . .

![Source : [ubuntu.com](https://ubuntu.com/blog/guide-to-ml-model-serving)](img/model-serving.png){fig-align="center" height=250}

## Cas d'usage

- Servir un mod√®le de ML via une API

## Les APIs

> Une API (application programming interface ou ¬´ interface de programmation d‚Äôapplication ¬ª) est une interface logicielle qui permet de ¬´ connecter ¬ª un logiciel ou un service √† un autre logiciel ou service afin d‚Äô√©changer des donn√©es et des fonctionnalit√©s.
>
> [CNIL](https://www.cnil.fr/fr/definition/interface-de-programmation-dapplication-api)

- D√©finition peu informative
    - `Python`, `scikit-learn`, `Docker`, etc. sont des APIs
    - En pratique, on signifie g√©n√©ralement une [**API REST**]{.blue2}

## Les APIs REST

- [**API RESTful**]{.orange} : API conforme au style d'architecture [REST](https://fr.wikipedia.org/wiki/Representational_state_transfer)
    - Communication via le [**protocole HTTP**]{.blue2}

- En pratique :
    - On requ√™te un [**endpoint**]{.blue2} (ex : [l'API de la BAN](https://api-adresse.data.gouv.fr/search/))
    - Avec des [**requ√™tes HTTP**]{.blue2} (`GET`, `POST`, etc.) (ex : [rues contenant "com√©die"](https://api-adresse.data.gouv.fr/search/?q=com√©die&type=street))

## Architecture cible

- Construire une [**API**]{.orange} pour [**servir**]{.orange} le mod√®le
    - [**Interface**]{.blue2} entre [**l'utilisateur**]{.blue2} et le [**mod√®le**]{.blue2} entra√Æn√©

. . .

![](img/api-no-mlflow.png){fig-align="center" height=400}

## Environnement de production

- D√©pend essentiellement de l'infrastructure √† disposition

- [**Propri√©t√©s recherch√©es**]{.orange} :
    - Adapter les ressources ([**scaler**]{.blue2}) selon les besoins
    - D√©ploiements [**reproductibles**]{.blue2} et [**automatis√©s**]{.blue2}
    - [**Monitoring**]{.blue2} de l'√©tat de sant√© des applications

- Solution : utiliser un [**orchestrateur de conteneurs**]{.orange}
    - Base du `SSP Cloud` : [Kubernetes](https://kubernetes.io/fr/)

. . .

![](img/kubernetes-logo.png){fig-align="center" height=100}

## Fonctionnement de Kubernetes

![Source : [DBA Consulting Blog](https://drsalbertspijkers.blogspot.com/2017/06/red-hat-openshift-and-orchestrating.html)](img/kubernetes-archi.png){fig-align="center"  height=400}

## L'approche CI/CD

- [**Int√©gration continue**]{.orange} (CI) : chaque commit d√©clenche un processus "[**test, build and release**]{.blue2}"
    - `GitHub` {{< fa brands github >}} : [GitHub Actions](https://github.com/features/actions)
    - `GitLab` {{< fa brands gitlab >}} : [GitLab CI/CD](https://docs.gitlab.com/ee/ci/)

- [**D√©ploiement continu**]{.orange} (CD) : les nouvelles [**releases**]{.blue2} sont automatiquement d√©ploy√©es
    - Sur le `SSP Cloud` : [ArgoCD](https://argo-cd.readthedocs.io/en/stable/)

## CI : impl√©mentation avec `GitHub Actions`

- [**Principe**]{.orange} : commit -> ex√©cution d'une s√©rie d'√©tapes
    - Script ex√©cut√© sur une VM : [***runner***]{.blue2}
    - Mise √† disposition d'un *output* : [***artifact***]{.blue2}

- [**Multiples outputs possibles**]{.orange}
    - [Image Docker](https://github.com/ensae-reproductibilite/application-correction/blob/appli19b/.github/workflows/prod.yml)
    - [Slides](https://github.com/ensae-reproductibilite/slides/blob/main/.github/workflows/publish.yaml)
    - [Site internet](https://github.com/ensae-reproductibilite/website/blob/main/.github/workflows/publish.yaml)

## CI : anatomie d'un fichier de CI

- Sp√©cification : fichier `.yaml` qui param√©trise le *runner*
    - ‚ö†Ô∏è Situ√© dans le dossier `.github/workflows/`

. . .

```{.yaml filename=".github/workflows/ci.yaml"}
name: Build Docker image

on:
  push:
    branches:
      - main
    tags:

jobs:
  docker:
    runs-on: ubuntu-latest
    steps:
      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      - name: Docker meta
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ensae-reproductibilite/api-titanic
      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}
      - name: Build and push
        uses: docker/build-push-action@v5
        with:
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
```

## CI/CD : impl√©mentation sur `Kubernetes`

![](img/ci-cd.png){fig-align="center" height=300}

## Pipeline [***DataOps***]{.orange} complet

- Int√©gration des √©tapes dans un [**pipeline**]{.orange} ([**DAG**]{.blue2})

. . .

![Source : [ubuntu.com](https://ubuntu.com/blog/data-pipelines-overview)](img/data-pipeline.png){fig-align="center" height=300}

- En pratique : utilisation d'un [**orchestrateur**]{.orange}
    - Sur le `SSP Cloud` : [Argo Workflows](https://argoproj.github.io/workflows/)

## Conclusion

- On a construit un pipeline [**reproductible**]{.orange} et [**automatis√©**]{.orange}

. . .

![Source : [ibm.com](https://public.dhe.ibm.com/software/data/sw-library/analytics/data-science-lifecycle/#model-implementation)](img/exploration-production.png){fig-align="center" height=250}

- Comment tenir compte des [**sp√©cificit√©s du ML**]{.orange} ?
    - [**Approche MLOps**]{.blue2}





# Application

## Mise en production

- Consignes sur le [site du cours](https://ensae-reproductibilite.github.io/website/chapters/application.html)
    - Partie :four: : [**automatisation**]{.blue2} de la livraison d'une application avec l‚Äô[**int√©gration continue**]{.blue2}
    - Partie :five: : [**d√©ploiement**]{.blue2} d'une application et [**industrialisation**]{.blue2}






# :eight: MLOps

## Motivation

- Int√©grer :
    - les [**principes DataOps**]{.orange}
    - les [**sp√©cificit√©s**]{.orange} des projets de ML

. . .

![Source : [ml4devs.com](https://www.ml4devs.com/articles/mlops-machine-learning-life-cycle/)](img/mlops.png){fig-align="center" height=400}

## MLOps : principes

- [**Reproductibilit√©**]{.orange}

- [**Contr√¥le de version**]{.orange}

- [**Automatisation**]{.orange}

- [**Collaboration**]{.orange}

- [**Monitoring**]{.orange}

## MLOps : impl√©mentation

- De nombreux [**frameworks**]{.orange} impl√©mentent les principes du MLOps
    - Catalogue du `SSP Cloud` : [MLFlow](https://mlflow.org/)

- Avantages de `MLflow` :
  - [**Open-source**]{.blue2}
  - Couvre l'enti√®ret√© du [**cycle de vie**]{.blue2} d'un mod√®le ML
  - [**Agnostique**]{.blue2} au package ML utilis√©
  - Int√©gration avec `Kubernetes`

## `MLFlow` : vue d'ensemble

![Source : [dzlab.github.io](https://dzlab.github.io/ml/2020/07/12/ml-ci-mlflow/)](img/mlflow-overview.png){fig-align="center" height=350}

## `MLFlow` : Tracking server

- "Une [**API**]{.orange} et une [**interface utilisateur**]{.orange} pour [**enregistrer**]{.orange} les param√®tres, les versions du code, les m√©triques et les artefacts"

. . .

![Source : [Databricks](https://docs.databricks.com/en/mlflow/index.html)](img/mlflow-tracking.png){fig-align="center" height=400}

## `MLFlow` : Models

- "Une convention pour [**'packager'**]{.orange} des [**mod√®les**]{.orange} de *machine learning* sous plusieurs [**formes**]{.orange}"

. . .

![Source : [Dataiku](https://blog.dataiku.com/introducing-mlflow-saved-models)](img/mlflow-models.png){fig-align="center" height=400}

## `MLFlow` : Model registry

- "Un [**entrep√¥t centralis√© de mod√®les**]{.orange}, un ensemble d'API et une interface utilisateur pour g√©rer [**collaborativement**]{.orange}  le cycle de vie complet d'un mod√®le MLflow"

. . .

![Source : [Databricks](https://www.databricks.com/blog/2019/10/17/introducing-the-mlflow-model-registry.html)](img/mlflow-model-registry.png){fig-align="center" height=400}

## Servir le mod√®le (sans `MLFlow`)

![](img/api-no-mlflow.png){fig-align="center"}

## Servir le mod√®le (avec `MLFlow`)

![](img/api-with-mlflow.png){fig-align="center"}

## Suivi du mod√®le

- Pourquoi [**surveiller**]{.orange} un mod√®le en production ?
    - D√©tecter d'√©ventuels [**biais**]{.blue2} des donn√©es d'entra√Ænement
    - D√©tecter une [**instabilit√©**]{.blue2} du mod√®le
    - [**Am√©lioration continue**]{.blue2} du mod√®le

- ‚ö†Ô∏è Le mot [**surveillance**]{.orange} d'une application/mod√®le recouvre des [**r√©alit√©s diff√©rentes**]{.blue2}

## Surveillance selon l'informaticien

- Surveiller une application est partie int√©grante de l'approche [**DevOps**]{.orange}

- Contr√¥le [**technique**]{.orange} de l'API :
    - Latence
    - M√©moire
    - Utilisation disque
    - ...

## Surveillance selon le data scientist

- Surveiller un mod√®le ML est partie int√©grante de l'approche [**MLOps**]{.orange}

- Contr√¥le [**m√©thodologique**]{.orange} du mod√®le

- Performance en [**temps r√©el**]{.orange} du mod√®le souvent impossible, utilisation de proxys :
    - [**Data drift**]{.blue2} : la distribution des donn√©es d'entr√©e change dans le temps
    - [**Concept drift**]{.blue2} : la relation mod√©lis√©e change dans le temps

## Comment surveiller un mod√®le en production ?

- Int√©gration de [**logs**]{.orange} dans l'API

- R√©cup√©ration et mise en forme des logs

- Suivi de [**m√©triques**]{.orange} de ML

- Mise en place d'un syst√®me d'[**alertes**]{.orange}

## R√©sultat : un pipeline reproductible

![Source: [martinfowler.com](martinfowler.com)](img/ML-model-lifecycle.png){fig-align="center"}






# Application

## MLOps

- Consignes sur le [site du cours](https://ensae-reproductibilite.github.io/website/chapters/application.html)
    - Partie :six: : application des [**principes MLOps**]{.blue2} avec `MLFlow`






# Conclusion

- La [**mise en production**]{.orange} met en lumi√®re le [**r√¥le d'interface**]{.orange}
    - De la [***data science***]{.blue2} : statistique et informatique
    - Du [***data scientist***]{.blue2} : √©quipes m√©tier et techniques

- Enjeu : adopter des [**modes d'organisation plus continus**]{.orange}
    - Des [**bonnes pratiques**]{.blue2} √† appliquer [**le plus t√¥t possible**]{.blue2}
    - [**Automatiser**]{.blue2} pour favoriser l'[**am√©lioration continue**]{.blue2}

- ‚ö†Ô∏è Ce cours pr√©sente une [**vision technique**]{.orange} du sujet
    - Les changements n√©cessaires sont plus larges !
